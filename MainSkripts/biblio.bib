@techreport{Gelman2017,
abstract = {The usual definition of R 2 (variance of the predicted values divided by the variance of the data) has a problem for Bayesian fits, as the numerator can be larger than the denominator. We propose an alternative definition similar to one that has appeared in the survival analysis literature: the variance of the predicted values divided by the variance of predicted values plus the variance of the errors. This summary is computed automatically for linear and generalized linear regression models fit using rstanarm, our R package for fitting Bayesian applied regression models with Stan.},
author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Ali, Imad},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Gelman et al. - 2017 - R-squared for Bayesian regression models(2).pdf:pdf},
title = {{R squared for Bayesian regression models *}},
url = {https://github.com/jgabry/bayes{\_}R2.},
year = {2017}
}
@article{Kvalseth1985,
abstract = {The coefficient of determination (R2) is perhaps the single most extensively used measure of goodness of fit for regression models. It is also widely misused. The primary source of the problem is that except for linear models with an intercept term, the several alternative R2 statistics are not generally equivalent. This article discusses various considerations and potential pitfalls in using the R2's. Specific points are exemplified by means of empirical data. A new resistant statistic is also introduced.},
archivePrefix = {arXiv},
arxivId = {10.2307/2683704},
author = {Kvalseth, Tarald O.},
doi = {10.2307/2683704},
eprint = {2683704},
isbn = {0003-1305},
issn = {00031305},
journal = {The American Statistician},
month = {nov},
number = {4},
pages = {279},
primaryClass = {10.2307},
publisher = {Taylor {\&} Francis, Ltd.American Statistical Association},
title = {{Cautionary Note about R 2}},
url = {http://www.jstor.org/stable/2683704?origin=crossref},
volume = {39},
year = {1985}
}
@techreport{Walsh2015,
author = {Walsh, Chris and Nally, Ralph Mac},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Walsh, Nally - 2015 - Title Hierarchical Partitioning.pdf:pdf},
title = {{Title Hierarchical Partitioning}},
url = {https://cran.r-project.org/web/packages/hier.part/hier.part.pdf},
year = {2015}
}
@article{Gromping2006,
abstract = {Relative importance is a topic that has seen a lot of interest in recent years, particularly in applied work. The R package relaimpo implements six different metrics for assessing relative importance of regressors in the linear model, two of which are recommended - averaging over orderings of regressors and a newly proposed metric (Feldman 2005) called pmvd. Apart from delivering the metrics themselves, relaimpo also provides (exploratory) bootstrap confidence intervals. This paper offers a brief tutorial introduction to the package. The methods and relaimpo's functionality are illustrated using the data set swiss that is generally available in R. The paper targets readers who have a basic understanding of multiple linear regression. For the background of more advanced aspects, references are provided.},
author = {Gr{\"{o}}mping, Ulrike},
doi = {10.18637/jss.v017.i01},
issn = {1548-7660},
journal = {Journal of Statistical Software},
month = {sep},
number = {1},
pages = {1--27},
title = {{Relative Importance for Linear Regression in R : The Package relaimpo}},
url = {http://www.jstatsoft.org/v17/i01/},
volume = {17},
year = {2006}
}
@article{Nimon2013,
abstract = {Multiple linear regression (MLR) remains a mainstay analysis in organizational research, yet inter-correlations between predictors (multicollinearity) undermine the interpretation of MLR weights in terms of predictor contributions to the criterion. Alternative indices include validity coefficients, structure coefficients, product measures, relative weights, all-possible-subsets regression, dominance weights, and commonality coefficients. This article reviews these indices, and uniquely, it offers freely available software that (a) computes and compares all of these indices with one another, (b) computes associated bootstrapped confidence intervals, and (c) does so for any number of pre-dictors so long as the correlation matrix is positive definite. Other available software is limited in all of these respects. We invite researchers to use this software to increase their insights when applying MLR to a data set. Avenues for future research and application are discussed. Keywords multiple regression, quantitative research, exploratory, research design A continued goal of organizational researchers conducting regression analysis is to make inferences about the relative importance of predictor variables (cf. Nimon, Gavrilova, {\&} Roberts, 2010; Zien-tek, Capraro, {\&} Capraro, 2008), yet it is all too common to rely heavily (if not solely) on the regression coefficients from the analysis which optimize sample-specific prediction (minimize sum of squared errors). Instead, other metrics that operationalize relative importance in ways that are consistent with such researchers' goals would seem more appropriate, and a range of metrics and approaches exists. In addition to regression weights and zero-order correlation coefficients that researchers likely report, MLR interpretation may be further informed by considering structure},
author = {Nimon, Kim F and Oswald, Frederick L},
doi = {10.1177/1094428113493929},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Nimon, Oswald - 2013 - Understanding the Results of Multiple Linear Regression Beyond Standardized Regression Coefficients.pdf:pdf},
journal = {Organizational Research Methods},
number = {0},
pages = {1--25},
title = {{Understanding the Results of Multiple Linear Regression: Beyond Standardized Regression Coefficients}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.923.7363{\&}rep=rep1{\&}type=pdf},
volume = {00},
year = {2013}
}
@article{Ray-Mukherjee2014,
abstract = {1. In the face of natural complexities and multicollinearity, model selection and predictions using multiple regression may be ambiguous and risky. Confounding effects of predictors often cloud researchers' assessment and interpretation of the single best 'magic model'. The shortcomings of step-wise regression have been extensively described in statistical literature, yet it is still widely used in ecological literature. Similarly, hierarchical regression which is thought to be an improvement of the stepwise procedure, fails to address multicollinearity. 2. We propose that regression commonality analysis (CA), a technique more commonly used in psychology and education research will be helpful in interpreting the typical multiple regression analyses conducted on ecological data. 3. CA decomposes the variance of R 2 into unique and common (or shared) variance (or effects) of pre-dictors, and hence, it can significantly improve exploratory capabilities in studies where multiple regressions are widely used, particularly when predictors are correlated. CA can explicitly identify the magnitude and location of multicollinearity and suppression in a regression model. In this paper, using a simulated (from a correlation matrix) and an empirical dataset (human habitat selection, migration of Canadians across cities), we demonstrate how CA can be used with correlated predictors in multiple regression to improve our understanding and interpretation of data. We strongly encourage the use of CA in ecological research as a follow-on analysis from multiple regressions .},
author = {Ray-Mukherjee, Jayanti and Nimon, Kim and Mukherjee, Shomen and Morris, Douglas W and Slotow, Rob and Hamer, Michelle},
doi = {10.1111/2041-210X.12166},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Ray-Mukherjee et al. - 2014 - Using commonality analysis in multiple regressions a tool to decompose regression effects in the face o(2).pdf:pdf},
keywords = {Key-words: stepwise regression,habitat selection,hierarchical regression,standardized partial regression coefficient,structure coefficients,suppressor variable},
title = {{Using commonality analysis in multiple regressions: a tool to decompose regression effects in the face of multicollinearity}},
url = {https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.12166},
year = {2014}
}
@article{Gromping2007,
abstract = {Assigning shares of "relative importance" to each of a set of regressors is one of the key goals of researchers applying linear regression, particularly in sciences that work with observational data.. Although the topic is quite old, advances in computational capabilities have led to increased applications of computer-intensive methods like averaging over orderings that enable a reasonable decomposition of the model variance. This article serves two purposes: to reconcile the large and somewhat fragmented body of recent literature on relative importance and to investigate the theoretical and empirical properties of the key competitors for decomposition of model variance.},
author = {Gr{\"{o}}mping, Ulrike},
doi = {10.1198/000313007X188252},
file = {:Users/silvano/Dokumente/Masterarbeit/Literatur/Groemping2007.pdf:pdf},
isbn = {000313007X},
issn = {00031305},
journal = {American Statistician},
keywords = {Averaging over orderings,Linear model,Proportional marginal variance decomposition (PMVD,Sequential sums of squares},
number = {2},
pages = {139--147},
title = {{Estimators of relative importance in linear regression based on variance decomposition}},
volume = {61},
year = {2007}
}
@article{Gromping2015,
abstract = {Regression analysis is one of the most-used statistical methods. Often part of the research question is the identification of the most important regressors or an importance ranking of the regressors. Most regression models are not specifically suited for answering the variable importance question, so that many different proposals have been made. This article reviews in detail the various variable importance metrics for the linear model, particularly emphasizing variance decomposition metrics. All linear model metrics are illustrated by an example analysis. For nonlinear parametric models, several principles from linear models have been adapted, and machine-learning methods have their own set of variable importance methods. These are also briefly covered. Although there are many variable importance metrics, there is still no convincing theoretical basis for them, and they all have a heuristic touch. Nevertheless, some metrics are considered useful for a crude assessment in the absence of a good subject matter theory. WIREs Comput Stat 2015, 7:137–152. doi: 10.1002/wics.1346},
author = {Gr{\"{o}}mping, Ulrike},
doi = {10.1002/wics.1346},
file = {:Users/silvano/Dokumente/Masterarbeit/Literatur/Groemping-2015-Wiley{\_}Interdisciplinary{\_}Reviews{\%}3A{\_}Computational{\_}Statistics.pdf:pdf},
isbn = {1939-0068},
issn = {19390068},
journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
keywords = {Correlated regressors,Hierarchical partitioning,Multiple regression,Relative importance},
number = {2},
pages = {137--152},
title = {{Variable importance in regression models}},
volume = {7},
year = {2015}
}
@article{Chevan1991,
author = {Chevan, Albert and Sutherland, Michael},
doi = {10.1080/00031305.1991.10475776},
issn = {0003-1305},
journal = {The American Statistician},
month = {may},
number = {2},
pages = {90--96},
title = {{Hierarchical Partitioning}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1991.10475776},
volume = {45},
year = {1991}
}
@article{Alexander2015,
abstract = {The statistical metrics used to characterize the external predictivity of a model, i.e., how well it predicts the properties of an independent test set, have proliferated over the past decade. This paper clarifies some apparent confusion over the use of the coefficient of determination, R(2), as a measure of model fit and predictive power in QSAR and QSPR modeling. R(2) (or r(2)) has been used in various contexts in the literature in conjunction with training and test data for both ordinary linear regression and regression through the origin as well as with linear and nonlinear regression models. We analyze the widely adopted model fit criteria suggested by Golbraikh and Tropsha ( J. Mol. Graphics Modell. 2002 , 20 , 269 - 276 ) in a strict statistical manner. Shortcomings in these criteria are identified, and a clearer and simpler alternative method to characterize model predictivity is provided. The intent is not to repeat the well-documented arguments for model validation using test data but rather to guide the application of R(2) as a model fit statistic. Examples are used to illustrate both correct and incorrect uses of R(2). Reporting the root-mean-square error or equivalent measures of dispersion, which are typically of more practical importance than R(2), is also encouraged, and important challenges in addressing the needs of different categories of users such as computational chemists, experimental scientists, and regulatory decision support specialists are outlined.},
author = {Alexander, D L J and Tropsha, A and Winkler, David A},
doi = {10.1021/acs.jcim.5b00206},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Alexander, Tropsha, Winkler - 2015 - Beware of R(2) Simple, Unambiguous Assessment of the Prediction Accuracy of QSAR and QSPR Models.pdf:pdf},
issn = {1549-960X},
journal = {Journal of chemical information and modeling},
month = {jul},
number = {7},
pages = {1316--22},
pmid = {26099013},
publisher = {NIH Public Access},
title = {{Beware of R(2): Simple, Unambiguous Assessment of the Prediction Accuracy of QSAR and QSPR Models.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26099013 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4530125},
volume = {55},
year = {2015}
}
@article{Nakagawa2013,
abstract = {*$\backslash$nThe use of both linear and generalized linear mixed-effects models (LMMs and GLMMs) has become popular not only in social and medical sciences, but also in biological sciences, especially in the field of ecology and evolution. Information criteria, such as Akaike Information Criterion (AIC), are usually presented as model comparison tools for mixed-effects models.$\backslash$n$\backslash$n$\backslash$n$\backslash$n*$\backslash$nThe presentation of ‘variance explained' (R2) as a relevant summarizing statistic of mixed-effects models, however, is rare, even though R2 is routinely reported for linear models (LMs) and also generalized linear models (GLMs). R2 has the extremely useful property of providing an absolute value for the goodness-of-fit of a model, which cannot be given by the information criteria. As a summary statistic that describes the amount of variance explained, R2 can also be a quantity of biological interest.$\backslash$n$\backslash$n$\backslash$n$\backslash$n*$\backslash$nOne reason for the under-appreciation of R2 for mixed-effects models lies in the fact that R2 can be defined in a number of ways. Furthermore, most definitions of R2 for mixed-effects have theoretical problems (e.g. decreased or negative R2 values in larger models) and/or their use is hindered by practical difficulties (e.g. implementation).$\backslash$n$\backslash$n$\backslash$n$\backslash$n*$\backslash$nHere, we make a case for the importance of reporting R2 for mixed-effects models. We first provide the common definitions of R2 for LMs and GLMs and discuss the key problems associated with calculating R2 for mixed-effects models. We then recommend a general and simple method for calculating two types of R2 (marginal and conditional R2) for both LMMs and GLMMs, which are less susceptible to common problems.$\backslash$n$\backslash$n$\backslash$n$\backslash$n*$\backslash$nThis method is illustrated by examples and can be widely employed by researchers in any fields of research, regardless of software packages used for fitting mixed-effects models. The proposed method has the potential to facilitate the presentation of R2 for a wide range of circumstances.},
archivePrefix = {arXiv},
arxivId = {2746},
author = {Nakagawa, Shinichi and Schielzeth, Holger},
doi = {10.1111/j.2041-210x.2012.00261.x},
editor = {O'Hara, Robert B.},
eprint = {2746},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Nakagawa, Schielzeth - 2013 - A general and simple method for obtaining iRi sup2sup from generalized linear mixed-effects models.pdf:pdf},
isbn = {2041-210X},
issn = {2041210X},
journal = {Methods in Ecology and Evolution},
keywords = {Coefficient of determination,Goodness-of-fit,Heritability,Information criteria,Intra-class correlation,Linear models,Model fit,Repeatability,Variance explained},
month = {feb},
number = {2},
pages = {133--142},
pmid = {11165473},
publisher = {Wiley/Blackwell (10.1111)},
title = {{A general and simple method for obtaining R2 from generalized linear mixed-effects models}},
url = {http://doi.wiley.com/10.1111/j.2041-210x.2012.00261.x},
volume = {4},
year = {2013}
}
@article{Nakagawa2017,
abstract = {The coefficient of determination R2 quantifies the proportion of variance explained by a statistical model and is an important summary statistic of biological interest. However, estimating R2 for generalized linear mixed models (GLMMs) remains challenging. We have previously introduced a version of R2 that we called [Formula: see text] for Poisson and binomial GLMMs, but not for other distributional families. Similarly, we earlier discussed how to estimate intra-class correlation coefficients (ICCs) using Poisson and binomial GLMMs. In this paper, we generalize our methods to all other non-Gaussian distributions, in particular to negative binomial and gamma distributions that are commonly used for modelling biological data. While expanding our approach, we highlight two useful concepts for biologists, Jensen's inequality and the delta method, both of which help us in understanding the properties of GLMMs. Jensen's inequality has important implications for biologically meaningful interpretation of GLMMs, whereas the delta method allows a general derivation of variance associated with non-Gaussian distributions. We also discuss some special considerations for binomial GLMMs with binary or proportion data. We illustrate the implementation of our extension by worked examples from the field of ecology and evolution in the R environment. However, our method can be used across disciplines and regardless of statistical environments.},
author = {Nakagawa, Shinichi and Johnson, Paul C D and Schielzeth, Holger},
doi = {10.1098/rsif.2017.0213},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Nakagawa, Johnson, Schielzeth - 2017 - The coefficient of determinationR2and intra-class correlation coefficient from generalized linear.pdf:pdf},
issn = {1742-5662},
journal = {Journal of the Royal Society, Interface},
keywords = {goodness of fit,heritability,model fit,reliability analysis,repeatability,variance decomposition},
month = {sep},
number = {134},
pmid = {28904005},
publisher = {The Royal Society},
title = {{The coefficient of determination R2 and intra-class correlation coefficient from generalized linear mixed-effects models revisited and expanded.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/28904005 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5636267},
volume = {14},
year = {2017}
}
