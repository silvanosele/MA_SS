@Manual{stanM2017,
  title     = {Stan Modeling Language: User's Guide and Reference Manual},
  author    = {{Stan Development Team}},
  year      = {2017},
  url       = {http://mc-stan.org/manual.html},
}


@book{Fitzmaurice2011,
abstract = {2nd ed. "Since the publication of the first edition, the authors have solicited feedback from both the instructors who use the book as a text for their courses as well as the researchers who use the book as a resource for their research. Thus, the improved Second Edition of Applied Longitudinal Analysis features many additions and revisions based on the feedback of readers, making it the go-to reference for applied use in public health, epidemiology, and pharmaceutical sciences"-- Longitudinal and clustered data -- Longitudinal data: basic concepts -- overview of linear models for longitudinal data -- Estimation and statistics inference -- Modeling the mean: analyzing response profiles -- Modeling the mean: parametric curves -- Modeling the covariance -- Linear mixed effect models -- Fixed effects versus random effects models -- Residual analyses and diagnostics -- Review  of generalized linear models -- Marginal models: introduction and overview -- Marginal models: generalized estimating equations (GEE) -- Generalized linear mixed effect models -- Generalized linear mixed effect models: approximate methods of estimation -- Contrasting marginal and mixed effects models -- Missing data and dropout: overview of concepts and methods -- Missing data and dropouts: multiple imputation and weighting methods -- Smoothing longitudinal data: semiparametric regression models -- Sample size and power -- Repeated measures and related designs -- Multilevel models},
author = {Fitzmaurice, Garrett M. and Laird, Nan M. and Ware, James H.},
isbn = {0470380276},
pages = {701},
publisher = {Wiley},
title = {{Applied longitudinal analysis}},
year = {2011}
}



@article{Nimon2008,
author = {Nimon, Kim and Lewis, Mitzi and Kane, Richard and Haynes, R. Michael},
doi = {10.3758/BRM.40.2.457},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Nimon et al. - 2008 - An R package to compute commonality coefficients in the multiple regression case An introduction to the package an.pdf:pdf},
issn = {1554-351X},
journal = {Behavior Research Methods},
month = {may},
number = {2},
pages = {457--466},
publisher = {Springer-Verlag},
title = {{An R package to compute commonality coefficients in the multiple regression case: An introduction to the package and a practical example}},
url = {http://www.springerlink.com/index/10.3758/BRM.40.2.457},
volume = {40},
year = {2008}
}


  @article{Holzinger1939,
address = {Chicago, Ill.,},
author = {Holzinger, Karl J. and Swineford, F.},
isbn = {Supplementary Educational Monographs, No. 48},
journal = {Supplementary Educational Monographs},
number = {9},
pages = {1--91},
publisher = {University of Chicago,},
title = {{A study in factor analysis: The stability of a bi-factor solution}},
url = {https://searchworks.stanford.edu/view/82773},
volume = {48},
year = {1939}
}
  
  @Misc{rstanarm,
    title = {rstanarm: {Bayesian} applied regression modeling via
      {Stan}.},
    author = {{Stan Development Team}},
    note = {R package version 2.13.1},
    year = {2016},
    url = {http://mc-stan.org/},
  }

  @Misc{MBESS,
    title = {MBESS (Version 4.0.0 and higher) [computer software and manual]},
    author = {Ken Kelley},
    note = {R package version  4.0.0 and higher},
    year = {2017},
    url = {https://www3.nd.edu/~kkelley/site/MBESS.html},
  }

@article{Link2012,
abstract = {1. Markov chain Monte Carlo (MCMC) is a simulation technique that has revolutionised the analysis of ecological data, allowing the fitting of complex models in a Bayesian framework. Since 2001, there have been nearly 200 papers using MCMC in publications of the Ecological Society of America and the British Ecological Society, including more than 75 in the journal Ecology and 35 in the Journal of Applied Ecology. 2. We have noted that many authors routinely `thin' their simulations, discarding all but every kth sampled value; of the studies we surveyed with details on MCMC implementation, 40{\{}{\%}{\}} reported thinning. 3. Thinning is often unnecessary and always inefficient, reducing the precision with which features of the Markov chain are summarised. The inefficiency of thinning MCMC output has been known since the early 1990's, long before MCMC appeared in ecological publications. 4. We discuss the background and prevalence of thinning, illustrate its consequences, discuss circumstances when it might be regarded as a reasonable option and recommend against routine thinning of chains unless necessitated by computer memory limitations.},
author = {Link, William A and Eaton, Mitchell J},
doi = {10.1111/j.2041-210X.2011.00131.x},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Link, Eaton - Unknown - On thinning of chains in MCMC.pdf:pdf},
isbn = {2041-210x},
issn = {2041210X},
journal = {Methods in Ecology and Evolution},
keywords = {Markov chain Monte Carlo,Thinning,WinBUGS},
number = {1},
pages = {112--115},
title = {{On thinning of chains in MCMC}},
url = {http://www.respond2articles.com/MEE/},
volume = {3},
year = {2012}
}
@article{Schafer2005,
abstract = {Inferring large-scale covariance matrices from sparse genomic data is an ubiquitous problem in bioinformatics. Clearly, the widely used standard covariance and correlation estimators are ill-suited for this purpose. As statistically efficient and computationally fast alternative we propose a novel shrinkage covariance estimator that exploits the Ledoit-Wolf (2003) lemma for analytic calculation of the optimal shrinkage intensity.Subsequently, we apply this improved covariance estimator (which has guaranteed minimum mean squared error, is well-conditioned, and is always positive definite even for small sample sizes) to the problem of inferring large-scale gene association networks. We show that it performs very favorably compared to competing approaches both in simulations as well as in application to real expression data.},
author = {Sch{\"{a}}fer, Juliane and Strimmer, Korbinian},
doi = {10.2202/1544-6115.1175},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Sch{\"{a}}fer et al. - Unknown - Statistical Applications in Genetics and Molecular Biology A Shrinkage Approach to Large-Scale Covariance Ma.pdf:pdf},
isbn = {1544-6115},
issn = {15446115},
journal = {Statistical Applications in Genetics and Molecular Biology},
keywords = {"small n,Covariance estimation,Gene expression,Genetic network,Graphical Gaussian model (GGM),Shrinkage,large p" problem},
number = {1},
pages = {1--30},
pmid = {16646851},
title = {{A shrinkage approach to large-scale covariance matrix estimation and implications for functional genomics}},
url = {http://www.bepress.com/sagmb},
volume = {4},
year = {2005}
}
@book{Jackman2009,
abstract = {Bayesian methods are increasingly being used in the social sciences, as the problems encountered lend themselves so naturally to the subjective qualities of Bayesian methodology. This book provides an accessible introduction to Bayesian methods, tailored specifically for social science students. It contains lots of real examples from political science, psychology, sociology, and economics, exercises in all chapters, and detailed descriptions of all the key concepts, without assuming any background in statistics beyond a first course. It features examples of how to implement the methods using WinBUGS – the most-widely used Bayesian analysis software in the world – and R – an open-source statistical software. The book is supported by a Website featuring WinBUGS and R code, data sets, and solutions to exercises.},
author = {Jackman, Simon},
doi = {10.1002/9780470686621},
isbn = {9780470686621},
issn = {1751-5823},
pages = {564},
publisher = {Wiley},
title = {{Bayesian Analysis for the Social Sciences}},
url = {https://www.wiley.com/en-us/Bayesian+Analysis+for+the+Social+Sciences-p-9780470011546 http://doi.wiley.com/10.1002/9780470686621},
year = {2009}
}
@techreport{Gelman2017,
abstract = {The usual definition of R 2 (variance of the predicted values divided by the variance of the data) has a problem for Bayesian fits, as the numerator can be larger than the denominator. We propose an alternative definition similar to one that has appeared in the survival analysis literature: the variance of the predicted values divided by the variance of predicted values plus the variance of the errors. This summary is computed automatically for linear and generalized linear regression models fit using rstanarm, our R package for fitting Bayesian applied regression models with Stan. 1. The problem Consider a regression model of outcomes y and predictors X with predicted values E(y|X, $\theta$), fit to data (X, y) n , n = 1, . . . , N . Ordinary least squares regression yields an estimated parameter vecto $\theta$ with predicted value y n = E(y|X n $\theta$) and residual variance V N n= y n , where we are using the notation, V N n=1 z n = 1 N − 1 N n=1 (z n − ¯ z) 2 , for any vector z. The proportion of variance explained, classical R 2 = V N n= y n V N n=1 y n , (1) is a commonly used measure of model fit, and there is a long literature on interpreting it, adjusting it for degrees of freedom used in fitting the model, and generalizing it to other settings such as hierarchical models; see Xu (2003) and Gelman and Pardoe (2006). Here we consider how to extend the concept of R 2 to apply to Bayesian model fitting. Our motivation is the rstanarm R package (Gabry and Goodrich, 2017) for fitting applied regression},
author = {Gelman, Andrew and Goodrich, Ben and Gabry, Jonah and Ali, Imad},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Gelman et al. - 2017 - R-squared for Bayesian regression models(2).pdf:pdf},
title = {{R-squared for Bayesian regression models *}},
url = {http://www.stat.columbia.edu/{~}gelman/research/unpublished/bayes{\_}R2.pdf},
year = {2017}
}
@article{Kvalseth1985,
abstract = {The coefficient of determination (R2) is perhaps the single most extensively used measure of goodness of fit for regression models. It is also widely misused. The primary source of the problem is that except for linear models with an intercept term, the several alternative R2 statistics are not generally equivalent. This article discusses various considerations and potential pitfalls in using the R2's. Specific points are exemplified by means of empirical data. A new resistant statistic is also introduced.},
archivePrefix = {arXiv},
arxivId = {10.2307/2683704},
author = {Kvalseth, Tarald O.},
doi = {10.2307/2683704},
eprint = {2683704},
isbn = {0003-1305},
issn = {00031305},
journal = {The American Statistician},
month = {nov},
number = {4},
pages = {279},
primaryClass = {10.2307},
publisher = {Taylor {\&} Francis, Ltd.American Statistical Association},
title = {{Cautionary Note about R 2}},
url = {http://www.jstor.org/stable/2683704?origin=crossref},
volume = {39},
year = {1985}
}
@techreport{Walsh2015,
author = {Walsh, Chris and Nally, Ralph Mac},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Walsh, Nally - 2015 - Title Hierarchical Partitioning.pdf:pdf},
title = {{Title Hierarchical Partitioning}},
url = {https://cran.r-project.org/web/packages/hier.part/hier.part.pdf},
year = {2015}
}
@article{Gromping2006,
abstract = {Relative importance is a topic that has seen a lot of interest in recent years, particularly in applied work. The R package relaimpo implements six different metrics for assessing relative importance of regressors in the linear model, two of which are recommended - averaging over orderings of regressors and a newly proposed metric (Feldman 2005) called pmvd. Apart from delivering the metrics themselves, relaimpo also provides (exploratory) bootstrap confidence intervals. This paper offers a brief tutorial introduction to the package. The methods and relaimpo's functionality are illustrated using the data set swiss that is generally available in R. The paper targets readers who have a basic understanding of multiple linear regression. For the background of more advanced aspects, references are provided.},
author = {Gr{\"{o}}mping, Ulrike},
doi = {10.18637/jss.v017.i01},
issn = {1548-7660},
journal = {Journal of Statistical Software},
month = {sep},
number = {1},
pages = {1--27},
title = {{Relative Importance for Linear Regression in R : The Package relaimpo}},
url = {http://www.jstatsoft.org/v17/i01/},
volume = {17},
year = {2006}
}
@article{Nimon2013,
abstract = {Multiple linear regression (MLR) remains a mainstay analysis in organizational research, yet inter-correlations between predictors (multicollinearity) undermine the interpretation of MLR weights in terms of predictor contributions to the criterion. Alternative indices include validity coefficients, structure coefficients, product measures, relative weights, all-possible-subsets regression, dominance weights, and commonality coefficients. This article reviews these indices, and uniquely, it offers freely available software that (a) computes and compares all of these indices with one another, (b) computes associated bootstrapped confidence intervals, and (c) does so for any number of pre-dictors so long as the correlation matrix is positive definite. Other available software is limited in all of these respects. We invite researchers to use this software to increase their insights when applying MLR to a data set. Avenues for future research and application are discussed. Keywords multiple regression, quantitative research, exploratory, research design A continued goal of organizational researchers conducting regression analysis is to make inferences about the relative importance of predictor variables (cf. Nimon, Gavrilova, {\&} Roberts, 2010; Zien-tek, Capraro, {\&} Capraro, 2008), yet it is all too common to rely heavily (if not solely) on the regression coefficients from the analysis which optimize sample-specific prediction (minimize sum of squared errors). Instead, other metrics that operationalize relative importance in ways that are consistent with such researchers' goals would seem more appropriate, and a range of metrics and approaches exists. In addition to regression weights and zero-order correlation coefficients that researchers likely report, MLR interpretation may be further informed by considering structure},
author = {Nimon, Kim F and Oswald, Frederick L},
doi = {10.1177/1094428113493929},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Nimon, Oswald - 2013 - Understanding the Results of Multiple Linear Regression Beyond Standardized Regression Coefficients.pdf:pdf},
journal = {Organizational Research Methods},
number = {0},
pages = {1--25},
title = {{Understanding the Results of Multiple Linear Regression: Beyond Standardized Regression Coefficients}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.923.7363{\&}rep=rep1{\&}type=pdf},
volume = {00},
year = {2013}
}
@article{Ray-Mukherjee2014,
abstract = {1. In the face of natural complexities and multicollinearity, model selection and predictions using multiple regression may be ambiguous and risky. Confounding effects of predictors often cloud researchers' assessment and interpretation of the single best ‘magicmodel'. The shortcomings of step- wise regression have been extensively described in statistical literature, yet it is still widely used in eco- logical literature. Similarly, hierarchical regression which is thought to be an improvement of the stepwise procedure, fails to addressmulticollinearity. 2. We propose that regression commonality analysis (CA), a techniquemore commonly used in psy- chology and education researchwill be helpful in interpreting the typicalmultiple regression analyses conducted on ecological data. 3.CAdecomposes the variance ofR2 into unique and common (or shared) variance (or effects) of pre- dictors, and hence, it can significantly improve exploratory capabilities in studies where multiple regressions are widely used, particularly when predictors are correlated. CA can explicitly identify themagnitude and location of multicollinearity and suppression in a regression model. In this paper, using a simulated (from a correlationmatrix) and an empirical dataset (human habitat selection,migration ofCanadians across cities), we demonstrate howCAcan be usedwith correlated predictors in multiple regression to improve our understanding and interpretation of data. We strongly encourage the use ofCAin ecological research as a follow-on analysis from multiple regressions.},
author = {Ray-Mukherjee, Jayanti and Nimon, Kim and Mukherjee, Shomen and Morris, Douglas W and Slotow, Rob and Hamer, Michelle},
doi = {10.1111/2041-210X.12166},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Ray-Mukherjee et al. - 2014 - Using commonality analysis in multiple regressions a tool to decompose regression effects in the face o(2).pdf:pdf},
isbn = {2041-210X},
issn = {2041210X},
journal = {Methods in Ecology and Evolution},
keywords = {Habitat selection,Hierarchical regression,Standardized partial regression coefficient,Stepwise regression,Structure coefficients,Suppressor variable},
number = {4},
pages = {320--328},
title = {{Using commonality analysis in multiple regressions: A tool to decompose regression effects in the face of multicollinearity}},
url = {https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.12166},
volume = {5},
year = {2014}
}
@article{Gromping2007,
abstract = {Assigning shares of "relative importance" to each of a set of regressors is one of the key goals of researchers applying linear regression, particularly in sciences that work with observational data.. Although the topic is quite old, advances in computational capabilities have led to increased applications of computer-intensive methods like averaging over orderings that enable a reasonable decomposition of the model variance. This article serves two purposes: to reconcile the large and somewhat fragmented body of recent literature on relative importance and to investigate the theoretical and empirical properties of the key competitors for decomposition of model variance.},
author = {Gr{\"{o}}mping, Ulrike},
doi = {10.1198/000313007X188252},
file = {:Users/silvano/Dokumente/Masterarbeit/Literatur/Groemping2007.pdf:pdf},
isbn = {000313007X},
issn = {00031305},
journal = {American Statistician},
keywords = {Averaging over orderings,Linear model,Proportional marginal variance decomposition (PMVD,Sequential sums of squares},
number = {2},
pages = {139--147},
title = {{Estimators of relative importance in linear regression based on variance decomposition}},
volume = {61},
year = {2007}
}
@article{Gromping2015,
abstract = {Regression analysis is one of the most-used statistical methods. Often part of the research question is the identification of the most important regressors or an importance ranking of the regressors. Most regression models are not specifically suited for answering the variable importance question, so that many different proposals have been made. This article reviews in detail the various variable importance metrics for the linear model, particularly emphasizing variance decomposition metrics. All linear model metrics are illustrated by an example analysis. For nonlinear parametric models, several principles from linear models have been adapted, and machine-learning methods have their own set of variable importance methods. These are also briefly covered. Although there are many variable importance metrics, there is still no convincing theoretical basis for them, and they all have a heuristic touch. Nevertheless, some metrics are considered useful for a crude assessment in the absence of a good subject matter theory. WIREs Comput Stat 2015, 7:137–152. doi: 10.1002/wics.1346},
author = {Gr{\"{o}}mping, Ulrike},
doi = {10.1002/wics.1346},
file = {:Users/silvano/Dokumente/Masterarbeit/Literatur/Groemping-2015-Wiley{\_}Interdisciplinary{\_}Reviews{\%}3A{\_}Computational{\_}Statistics.pdf:pdf},
isbn = {1939-0068},
issn = {19390068},
journal = {Wiley Interdisciplinary Reviews: Computational Statistics},
keywords = {Correlated regressors,Hierarchical partitioning,Multiple regression,Relative importance},
number = {2},
pages = {137--152},
title = {{Variable importance in regression models}},
volume = {7},
year = {2015}
}
@article{Chevan1991,
abstract = {Many users of regression methods are attracted to the notion that it$\backslash$nwould be valuable to determine the relative importance of independent$\backslash$nvariables. This article demonstrates a method based on hierarchies that$\backslash$nbuilds on previous efforts to decompose R2 through incremental$\backslash$npartitioning. The standard method of incremental partitioning has been$\backslash$nto follow one order among the many possible orders available. By taking$\backslash$na hierarchical approach in which all orders of variables are used, the$\backslash$naverage independent contribution of a variable is obtained and an exact$\backslash$npartitioning results. Much the same logic is used to divide the joint$\backslash$neffect of a variable. The method is general and applicable to all$\backslash$nregression methods, including ordinary least squares, logistic, probit,$\backslash$nand loglinear regression. A validation test demonstrates that the$\backslash$nalgorithm is sensitive to the relationships in the data rather than the$\backslash$nproportion of variability accounted for by the statistical model used.},
author = {Chevan, Albert and Sutherland, Michael},
doi = {10.1080/00031305.1991.10475776},
isbn = {0003-1305},
issn = {15372731},
journal = {American Statistician},
keywords = {Decomposition,Regression},
month = {may},
number = {2},
pages = {90--96},
pmid = {19601954},
title = {{Hierarchical partitioning}},
url = {http://www.tandfonline.com/doi/abs/10.1080/00031305.1991.10475776},
volume = {45},
year = {1991}
}
@article{Alexander2015,
abstract = {The statistical metrics used to characterize the external predictivity of a model, i.e., how well it predicts the properties of an independent test set, have proliferated over the past decade. This paper clarifies some apparent confusion over the use of the coefficient of determination, R(2), as a measure of model fit and predictive power in QSAR and QSPR modeling. R(2) (or r(2)) has been used in various contexts in the literature in conjunction with training and test data for both ordinary linear regression and regression through the origin as well as with linear and nonlinear regression models. We analyze the widely adopted model fit criteria suggested by Golbraikh and Tropsha ( J. Mol. Graphics Modell. 2002 , 20 , 269 - 276 ) in a strict statistical manner. Shortcomings in these criteria are identified, and a clearer and simpler alternative method to characterize model predictivity is provided. The intent is not to repeat the well-documented arguments for model validation using test data but rather to guide the application of R(2) as a model fit statistic. Examples are used to illustrate both correct and incorrect uses of R(2). Reporting the root-mean-square error or equivalent measures of dispersion, which are typically of more practical importance than R(2), is also encouraged, and important challenges in addressing the needs of different categories of users such as computational chemists, experimental scientists, and regulatory decision support specialists are outlined.},
archivePrefix = {arXiv},
arxivId = {15334406},
author = {Alexander, D. L.J. and Tropsha, A and Winkler, David A},
doi = {10.1021/acs.jcim.5b00206},
eprint = {15334406},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Alexander, Tropsha, Winkler - 2015 - Beware of R(2) Simple, Unambiguous Assessment of the Prediction Accuracy of QSAR and QSPR Models.pdf:pdf},
isbn = {0000287431},
issn = {15205142},
journal = {Journal of Chemical Information and Modeling},
month = {jul},
number = {7},
pages = {1316--1322},
pmid = {26099013},
publisher = {NIH Public Access},
title = {{Beware of R2: Simple, Unambiguous Assessment of the Prediction Accuracy of QSAR and QSPR Models}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/26099013 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC4530125},
volume = {55},
year = {2015}
}
@article{Nakagawa2013,
abstract = {*$\backslash$nThe use of both linear and generalized linear mixed-effects models (LMMs and GLMMs) has become popular not only in social and medical sciences, but also in biological sciences, especially in the field of ecology and evolution. Information criteria, such as Akaike Information Criterion (AIC), are usually presented as model comparison tools for mixed-effects models.$\backslash$n$\backslash$n$\backslash$n$\backslash$n*$\backslash$nThe presentation of ‘variance explained' (R2) as a relevant summarizing statistic of mixed-effects models, however, is rare, even though R2 is routinely reported for linear models (LMs) and also generalized linear models (GLMs). R2 has the extremely useful property of providing an absolute value for the goodness-of-fit of a model, which cannot be given by the information criteria. As a summary statistic that describes the amount of variance explained, R2 can also be a quantity of biological interest.$\backslash$n$\backslash$n$\backslash$n$\backslash$n*$\backslash$nOne reason for the under-appreciation of R2 for mixed-effects models lies in the fact that R2 can be defined in a number of ways. Furthermore, most definitions of R2 for mixed-effects have theoretical problems (e.g. decreased or negative R2 values in larger models) and/or their use is hindered by practical difficulties (e.g. implementation).$\backslash$n$\backslash$n$\backslash$n$\backslash$n*$\backslash$nHere, we make a case for the importance of reporting R2 for mixed-effects models. We first provide the common definitions of R2 for LMs and GLMs and discuss the key problems associated with calculating R2 for mixed-effects models. We then recommend a general and simple method for calculating two types of R2 (marginal and conditional R2) for both LMMs and GLMMs, which are less susceptible to common problems.$\backslash$n$\backslash$n$\backslash$n$\backslash$n*$\backslash$nThis method is illustrated by examples and can be widely employed by researchers in any fields of research, regardless of software packages used for fitting mixed-effects models. The proposed method has the potential to facilitate the presentation of R2 for a wide range of circumstances.},
archivePrefix = {arXiv},
arxivId = {2746},
author = {Nakagawa, Shinichi and Schielzeth, Holger},
doi = {10.1111/j.2041-210x.2012.00261.x},
editor = {O'Hara, Robert B.},
eprint = {2746},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Nakagawa, Schielzeth - 2013 - A general and simple method for obtaining iRi sup2sup from generalized linear mixed-effects models.pdf:pdf},
isbn = {2041-210X},
issn = {2041210X},
journal = {Methods in Ecology and Evolution},
keywords = {Coefficient of determination,Goodness-of-fit,Heritability,Information criteria,Intra-class correlation,Linear models,Model fit,Repeatability,Variance explained},
month = {feb},
number = {2},
pages = {133--142},
pmid = {11165473},
publisher = {Wiley/Blackwell (10.1111)},
title = {{A general and simple method for obtaining R2 from generalized linear mixed-effects models}},
url = {http://doi.wiley.com/10.1111/j.2041-210x.2012.00261.x},
volume = {4},
year = {2013}
}
@article{Nakagawa2017,
abstract = {The coefficient of determination R2 quantifies the proportion of variance explained by a statistical model and is an important summary statistic of biological interest. However, estimating R2 for generalized linear mixed models (GLMMs) remains challenging. We have previously introduced a version of R2 that we called Embedded Image for Poisson and binomial GLMMs, but not for other distributional families. Similarly, we earlier discussed how to estimate intra-class correlation coefficients (ICCs) using Poisson and binomial GLMMs. In this paper, we generalize our methods to all other non-Gaussian distributions, in particular to negative binomial and gamma distributions that are commonly used for modelling biological data. While expanding our approach, we highlight two useful concepts for biologists, Jensen's inequality and the delta method, both of which help us in understanding the properties of GLMMs. Jensen's inequality has important implications for biologically meaningful interpretation of GLMMs, whereas the delta method allows a general derivation of variance associated with non-Gaussian distributions. We also discuss some special considerations for binomial GLMMs with binary or proportion data. We illustrate the implementation of our extension by worked examples from the field of ecology and evolution in the R environment. However, our method can be used across disciplines and regardless of statistical environments.},
author = {Nakagawa, Shinichi and Johnson, Paul C D and Schielzeth, Holger},
doi = {10.1098/rsif.2017.0213},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Nakagawa, Johnson, Schielzeth - 2017 - The coefficient of determinationR2and intra-class correlation coefficient from generalized linear.pdf:pdf},
isbn = {0000000277655},
issn = {1742-5689},
journal = {Journal of The Royal Society Interface},
keywords = {goodness of fit,heritability,model fit,reliability analysis,repeatability,variance decomposition},
month = {sep},
number = {134},
pages = {20170213},
pmid = {28904005},
publisher = {The Royal Society},
title = {{The coefficient of determination R 2 and intra-class correlation coefficient from generalized linear mixed-effects models revisited and expanded}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/28904005 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC5636267 http://rsif.royalsocietypublishing.org/lookup/doi/10.1098/rsif.2017.0213},
volume = {14},
year = {2017}
}

@article{Bland1995,
abstract = {In an earlier Statistics Note1 we commented on the analysis of paired data where there is more than one observation per subject, as shown in table I. We pointed out that it could be highly misleading to analyse such data by combining repeated observations from several subjects and then calculating the correlation coefficient as if the data were a simple sample. This note is a response to several letters about the appropriate analysis for such data. View this table: TABLE I Repeated measurements of intramural pH and PaCO2 for eight subjects2 The choice of analysis for the data in table I depends on the question we want to {\ldots}},
author = {Bland, J M and Altman, D G},
doi = {10.1136/BMJ.310.6977.446},
file = {:Users/silvano/Library/Application Support/Mendeley Desktop/Downloaded/Bland, Altman - 1995 - Calculating correlation coefficients with repeated observations Part 1--Correlation within subjects.pdf:pdf},
issn = {0959-8138},
journal = {BMJ (Clinical research ed.)},
month = {feb},
number = {6977},
pages = {446},
pmid = {7873953},
publisher = {British Medical Journal Publishing Group},
title = {{Calculating correlation coefficients with repeated observations: Part 1--Correlation within subjects.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/7873953 http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=PMC2548822},
volume = {310},
year = {1995}
}

